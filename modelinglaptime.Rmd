<<<<<<< Updated upstream
---
title: "Modeling Avg Lap Time for Racers and Constructors"
output:
  github_document:
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
```

```{r load data, include=FALSE}
df_avglaptime <- read_csv("processed_data/avglaptime.csv")
```

### EDA

```{r data checks, include = FALSE}
df_avglaptime %>% 
  glimpse()

df_avglaptime %>% 
  summary()
```

## Histograms

```{r variable histgrams}
df_avglaptime %>% 
  filter(avg_lap <= 200000) %>% 
  ggplot(aes(avg_lap)) + 
  geom_histogram(bins = 50) + 
  labs(
    title = "Average Lap Time Histogram", 
    x = "Average Lap Time (ms)"
  ) + 
  theme_minimal()

df_avglaptime %>% 
  ggplot(aes(circuit_avg_lap)) + 
  geom_histogram(bins = 60) + 
  labs(
    title = "Circuit Average Lap Time Histogram", 
    x = "Average Circuit Lap Time (ms)"
  ) + 
  theme_minimal()
```

```{r circuit average lap}
df_avglaptime %>% 
  mutate(
    year = as.factor(year), 
    circuit_name = fct_reorder(circuit_name, circuit_avg_lap)) %>% 
  ggplot(aes(circuit_name, circuit_avg_lap)) + 
  geom_jitter(aes(color = year), alpha = 1/14) +
  coord_flip() + 
  labs(title = "Circuit Average Lap for GPs containing Drivers Who Have Driven For Multiple Teams") +
  theme_minimal() +
  theme(plot.title = element_text(size = 9))
```
***Observations***

- Same Grands Prix can have vastly different times, most likely due to different courses under the same GP name
  - See United States GP and French GP
- Also the circuit average lap time seems to diverge onto one time and doesn't seem to diverge much
- `SO MUCH data` that it is hard to visualize the number of observations for a single GP 
  - What is the best way to visualize these observations??
  
### Modeling 

## Creating data frames

```{r data loading, include = FALSE}
df_stdavglap <- read_csv("processed_data/std_avg_laptime.csv")

# Creating row ID column for anti_join
df_stdavglap <- tibble::rowid_to_column(df_stdavglap, "ID")
```

## Visualizing Std Average Lap Time

```{r}
df_stdavglap %>% 
  ggplot(aes(std_avg_lap)) +
  geom_histogram(bins = 50)
```


## Creating Model

```{r modeling the entire data set}

fullfit_driver <-
  df_stdavglap %>%
  lm(
    data = .,
    formula = positionOrder ~ as.factor(driverId)
  )

print("Full Fit - Just Driver")
cat("Rsquare", rsquare(fullfit_driver, df_stdavglap), "\n")
cat("MSE", mse(fullfit_driver, df_stdavglap), "\n")

fullfit_constructor <- 
  df_stdavglap %>% 
  lm(
    data = .,
    formula = positionOrder ~ as.factor(constructorId)
  )

print("Full Fit - Just Constructor")
cat("Rsquare", rsquare(fullfit_constructor, df_stdavglap), "\n")
cat("MSE", mse(fullfit_constructor, df_stdavglap), "\n")

fullfit_driver_constructor <- 
  df_stdavglap %>% 
  lm(
    data = .,
    formula = positionOrder ~ as.factor(driverId) + as.factor(constructorId)
  )

print("Full Fit - Driver and Constructor")
cat("Rsquare", rsquare(fullfit_driver_constructor, df_stdavglap), "\n")
cat("MSE", mse(fullfit_driver_constructor, df_stdavglap), "\n")
```

***Observations***

- Looking at our mean square error first we can compare our different models against one another
  - Between models, the error is lowest with both `driver and constructor` which is a good sign that both are informative towards lap time
- The order of best model to worst, solely based upon MSE, is driver & constructor, just driver, and finally just constructor
  - These results may imply that driver is a better predictor of outcome than constructor, but I will argue why not next
- Looking next at our rsquared  value we see that our models do **not** have very good coverage of the data
- We are looking at each model only covering around `5.7% to 8.1%` of the data, which calls into validity the comparisons made for our MSE
- The order of best model to worst, solely based upon rsquare, is driver & constructor, just driver, and finally just constructor
- So overall, the overall standings seem to follow the exact same trend seen in both MSE and rsquare
- These models should be taken with a grain or more of salt as we are using the entire data set to create these linear models
- Next, we'll see how constructor and driver stacks up against a training and validation data set


```{r train and validate data frames}
#Setting seed for temporary repeatability
#set.seed("101")

#Getting number of observations to feed into n for df_train
number_obs <- df_stdavglap %>% 
  group_by(driverId, circuitId) %>% 
  summarize(n = n()) %>% 
  pull(n)

#Sampling by 
df_train <-
  df_stdavglap %>%
  group_by(driverId, circuitId) %>% 
  slice_sample(n = 2) %>% 
  ungroup()

df_validate <-
  anti_join(
    df_stdavglap,
    df_train,
    by = "ID"
  )

df_train %>% arrange(ID)
df_validate %>% arrange(ID)
```

```{r modeling with training and validation data frames}

trainfit_driver <-
  df_train %>%
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(driverId)
  )

print("Train Fit - Just Driver")
cat("Rsquare", rsquare(trainfit_driver, df_validate), "\n")
cat("MSE", mse(trainfit_driver, df_validate), "\n")

trainfit_constructor <- 
  df_train %>% 
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(constructorId)
  )

print("Train Fit - Just Constructor")
cat("Rsquare", rsquare(trainfit_constructor, df_validate), "\n")
cat("MSE", mse(trainfit_constructor, df_validate), "\n")

trainfit_driver_constructor <- 
  df_train %>% 
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(driverId) + as.factor(constructorId)
  )

print("Train Fit - Driver and Constructor")
cat("Rsquare", rsquare(trainfit_driver_constructor, df_validate), "\n")
cat("MSE", mse(trainfit_driver_constructor, df_validate), "\n")
```

***Observations*** 


```{r}
driver_levels <- df_stdavglap %>% 
  mutate(driverId = as.factor(driverId)) %>% 
  pull(driverId) %>% 
  levels()
  
driver_levels
df_stdavglap

df_test <- 
  df_stdavglap %>% 
  select(driverId, constructorId) %>% 
  mutate(driverId = as.factor(driverId),
         constructorId = as.factor(constructorId))

tibble(df_test) %>% 
  add_predictions(trainfit_driver, var = "sal_pred-d") %>%
  add_predictions(trainfit_constructor, var = "sal_pred-c") %>%
  add_predictions(trainfit_constructor, var = "sal_pred-d+c") %>%  
  pivot_longer(
    names_to = c(".value", "model"),
    names_sep = "-",
    cols = matches("sal")
  ) %>% 
  ggplot(aes(driverId, sal_pred, color = model)) +
  geom_line(aes(group = model), alpha = .5) +
  geom_point(alpha = .5) +
  theme_minimal() +
  theme(
    aspect.ratio= 2/3,
    axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 0) 
    )
```


=======
---
title: "Modeling Avg Lap Time for Racers and Constructors"
output:
  github_document:
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(modelr)
```

```{r load data, include=FALSE}
df_avglaptime <- read_csv("processed_data/avglaptime.csv")
df_formula
```

### EDA

```{r data checks, include = FALSE}
df_avglaptime %>% 
  glimpse()

df_avglaptime %>% 
  summary()
```

## Historgrams

```{r variable histgrams}
df_avglaptime %>% 
  filter(avg_lap <= 200000) %>% 
  ggplot(aes(avg_lap)) + 
  geom_histogram(bins = 50) +
  labs(
    title = "Average Lap Time Histogram", 
    x = "Average Lap Time (ms)"
  ) + 
  theme_minimal()

df_avglaptime %>% 
  ggplot(aes(circuit_avg_lap)) + 
  geom_histogram(bins = 60) + 
  labs(
    title = "Circuit Average Lap Time Histogram", 
    x = "Average Circuit Lap Time (ms)"
  ) + 
  theme_minimal()
```

```{r circuit average lap}
df_avglaptime %>% 
  mutate(
    year = as.factor(year), 
    circuit_name = fct_reorder(circuit_name, circuit_avg_lap)) %>% 
  ggplot(aes(circuit_name, circuit_avg_lap)) + 
  geom_jitter(aes(color = year), alpha = 1/14) +
  coord_flip() + 
  labs(title = "Circuit Average Lap for GPs containing Drivers Who Have Driven For Multiple Teams") +
  theme_minimal() +
  theme(plot.title = element_text(size = 9))
```
***Observations***

- Same Grands Prix can have vastly different times, most likely due to different courses under the same GP name
  - See United States GP and French GP
- Also the circuit average lap time seems to diverge onto one time and doesn't seem to diverge much
- `SO MUCH data` that it is hard to visualize the number of observations for a single GP 
  - What is the best way to visualize these observations??
  
### Modeling Using Standard Average Lap Time


## Visualizing Std Average Lap Time

```{r}
df_stdavglap %>% 
  ggplot(aes(std_avg_lap)) +
  geom_histogram(bins = 50)
```


## Creating Model

```{r modeling the entire data set}

fullfit_driver <-
  df_stdavglap %>%
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(driverId)
  )

print("Full Fit - Just Driver")
cat("Rsquare", rsquare(fullfit_driver, df_stdavglap), "\n")
cat("MSE", mse(fullfit_driver, df_stdavglap), "\n")

fullfit_constructor <- 
  df_stdavglap %>% 
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(constructorId)
  )

print("Full Fit - Just Constructor")
cat("Rsquare", rsquare(fullfit_constructor, df_stdavglap), "\n")
cat("MSE", mse(fullfit_constructor, df_stdavglap), "\n")

fullfit_driver_constructor <- 
  df_stdavglap %>% 
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(driverId) + as.factor(constructorId)
  )

print("Full Fit - Driver and Constructor")
cat("Rsquare", rsquare(fullfit_driver_constructor, df_stdavglap), "\n")
cat("MSE", mse(fullfit_driver_constructor, df_stdavglap), "\n")
```

***Observations***

- Looking at our mean square error first we can compare our different models against one another
  - Between models, the error is lowest with both `driver and constructor` which is a good sign that both are informative towards lap time
- The order of best model to worst, solely based upon MSE, is driver & constructor, just driver, and finally just constructor
  - These results may imply that driver is a better predictor of outcome than constructor, but I will argue why not next
- Looking next at our rsquared  value we see that our models do **not** have very good coverage of the data
- We are looking at each model only covering around `5.7% to 8.1%` of the data, which calls into validity the comparisons made for our MSE
- The order of best model to worst, solely based upon rsquare, is driver & constructor, just driver, and finally just constructor
- So overall, the overall standings seem to follow the exact same trend seen in both MSE and rsquare
- These models should be taken with a grain or more of salt as we are using the entire data set to create these linear models
- Next, we'll see how constructor and driver stacks up against a training and validation data set

## Creating Train and Validation Data Frames

```{r data loading, include = FALSE}
df_stdavglap <- read_csv("processed_data/std_avg_laptime.csv")

# Creating row ID column for anti_join
df_stdavglap <- tibble::rowid_to_column(df_stdavglap, "ID")
```

```{r train and validate data frames}
#Setting seed for temporary repeatability
#set.seed("101")

#Getting number of observations to feed into n for df_train
number_obs <- df_stdavglap %>% 
  group_by(driverId, circuitId) %>% 
  summarize(n = n()) %>% 
  pull(n)

#Sampling by 
df_train <-
  df_stdavglap %>%
  group_by(driverId, circuitId) %>% 
  slice_sample(n = 2) %>% 
  ungroup()

df_validate <-
  anti_join(
    df_stdavglap,
    df_train,
    by = "ID"
  )

df_train %>% arrange(ID)
df_validate %>% arrange(ID)
```

```{r modeling with training and validation data frames}

trainfit_driver <-
  df_train %>%
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(driverId)
  )

print("Train Fit - Just Driver")
cat("Rsquare", rsquare(trainfit_driver, df_validate), "\n")
cat("MSE", mse(trainfit_driver, df_validate), "\n")

trainfit_constructor <- 
  df_train %>% 
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(constructorId)
  )

print("Train Fit - Just Constructor")
cat("Rsquare", rsquare(trainfit_constructor, df_validate), "\n")
cat("MSE", mse(trainfit_constructor, df_validate), "\n")

trainfit_driver_constructor <- 
  df_train %>% 
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(driverId) + as.factor(constructorId)
  )

print("Train Fit - Driver and Constructor")
cat("Rsquare", rsquare(trainfit_driver_constructor, df_validate), "\n")
cat("MSE", mse(trainfit_driver_constructor, df_validate), "\n")
```

***Observations*** 

## Visualizing Prediction 

```{r}
names <- 
  df_stdavglap %>% 
  select(driverId, constructorId) %>% 
  mutate(driverId = as.factor(driverId),
         constructorId = as.factor(constructorId))

tibble(names) %>% 
  add_predictions(trainfit_driver, var = "sal_pred-d") %>%
  add_predictions(trainfit_constructor, var = "sal_pred-c") %>%
  add_predictions(trainfit_constructor, var = "sal_pred-d+c") %>%  
  pivot_longer(
    names_to = c(".value", "model"),
    names_sep = "-",
    cols = matches("sal")
  ) %>% 
  ggplot(aes(driverId, sal_pred, color = model)) +
  geom_line(aes(group = model), alpha = .5) +
  geom_point(size = .5, alpha = .5) +
  theme_minimal() +
  theme(
    aspect.ratio= 2/3,
    text = element_text(size = 5), 
    axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 0,
                               ) 
    )
```

### Modeling Using Position Order
>>>>>>> Stashed changes
