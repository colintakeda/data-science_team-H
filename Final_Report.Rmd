---
title: ""
author: "Lilo Heinrich, Tim Novak, and Colin Takeda"
date: 12-14-2020
output:
  github_document:
    toc: true
  pdf_document:
    toc: true
---
 
<center> <h1>Formula 1 Racing: <br /> Does the car or the driver have the greater impact?</h1> </center>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(modelr)

df_timedata <- read_csv("processed_data/std_avg_laptime.csv")
df_data <- read_csv("processed_data/clean_f1.csv")
```

## Data Background

#### Context
The Formula 1 World Championship has been one of the premier forms of auto racing around the world since its inaugural season in 1950. The word "formula" refers to the set of rules to which all participants' cars must conform. A Formula 1 season consists of a series of Grands Prix races which take place worldwide on circuits and closed public roads.

#### Source
The [Formula 1 World Championships](https://www.kaggle.com/rohanrao/formula-1-world-championship-1950-2020) dataset consists of all information on the Formula 1 races, drivers, constructors, qualifying, circuits, lap times, pit stops, and championships for every season from 1950 to 2020.

This dataset was published by Rohan Rao, a Data Scientist who goes by the name [Vopani](https://www.kaggle.com/rohanrao) on Kaggle. (Fun fact: he is also the reigning National Sudoku Champion of India.) He compiled this dataset using the [Ergast Developer API](http://ergast.com/mrd/), an experimental web service that provides a historical record of motor racing data for non-commercial purposes. The API provides data specifically for the Formula One series, from the beginning of the world championships in 1950 up to the present season.

The Ergast API website does not give any details about their data collection procedures, but their data is very thorough and complete. Additionally, Formula 1 world championships are internationally televised and race results are publicly accessible information [(see official Formula 1 website)](https://www.formula1.com/en/results.html), so there is no reason to doubt the accuracy of the data reported.


----------------------------------------

## Investigation Question

#### Does the car or the driver have the greater impact?

Unlike most sports, Formula 1 racing is heavily reliant on the performance capability of their equipment, which is their cars that are created by the constructors. To what extent do the constructor and driver predict race performance, and which one has the greater predictive capability?

----------------------------------------

## Data Tidying

The data came in many separate files, including `results.csv`, `drivers.csv`, `constructors.csv`, `circuits.csv`, `races.csv`, `status.csv`, and `laptimes.csv`. Our first step was to join all of these data frames together by their relevant ID numbers and replace the missing values with `NA`.

In our dataset we kept these columns: 

- resultId
- raceId
- driverId
- constructorId
- positionOrder
- laps
- fastestLapSpeed
- statusId
- driver_name
- constructor_name
- year
- round
- circuitId
- race_name
- status
- circuit_name

```{r, include=FALSE}
#df_data %>% glimpse()
```

#### Time data

The column `milliseconds` reports the race completion time for all of the drivers that were able to finish the race. However, drivers are often unable to complete the full race due to collisions, car breakdowns, or other problems, leaving many missing values for total race time. We discarded `milliseconds` and created a second dataset where we supplemented information from `laptimes.csv` to compute total race time even when race status was not finished. The lap times were understandably missing when the number of laps completed was 0, so we removed these observations. Overall, we still only have lap times for 9,233 of our 24,900 though. 

In this time-filtered dataset we added these columns: 

- total_time
- avg_lap
- circuit_avg_lap
- circuit_lap_sd
- std_avg_lap

```{r, include=FALSE}
#df_timedata %>% glimpse()
```

#### Changes in racing ruleset/vehicle design through the years

This data is for 70 years of races and over that period of time [formula racing has changed a lot](https://youtu.be/hgLQWIAaCmY). This means that many factors will change through the years depending on the rule set that has been put in place. To help mitigate this problem we decided to filter down to the subset of data which follows the most recent set of rules for the races. The [most recent significant set of rules](https://en.wikipedia.org/wiki/Formula_One_engines#2014%E2%80%932021) dates back to 2014 where the allowed engine specifications were changed. Thus we filtered our data to only examine the data from 2014 onwards.

#### Potential Problems

- Some examples of [constructor name changes](https://www.reddit.com/r/formula1/comments/1dos3r/i_made_a_diagram_to_show_how_current_f1_teams/)
- New drivers are skewed because they don't have as many data points yet
- Teams and drivers are correlated, in that the best drivers tend to get hired by the best teams.

----------------------------------------

## Exploratory Data Analysis
 
#### Standardized Average Lap Time

```{r finish race, echo=FALSE}
df_data %>% 
  group_by(positionOrder) %>%
  mutate(mean_laps = mean(laps)) %>%
  ungroup() %>%
  ggplot(aes(positionOrder, mean_laps)) +
  geom_point() + 
  labs(
    y = "Mean laps completed",
    x = "Final position"
  ) + 
  theme_minimal() + 
  geom_line(color = "blue")
```

As shown in the graph above, final position is heavily reliant on how many laps the driver was able to complete. And almost a third of the time, collisions or car troubles put drivers out of commission before the race is finished. These final standings are not reflective of how well the driver was doing before that point, so we decided to use average lap time to create a more comprehensive performance metric.

Average lap time is a comprehensive measure of how well a driver performed in a race because it is informed only on the laps they were able to complete, unlike final position. The only problem is that it doesn't account for the effect of circuit on lap time, so we need to correct for this difference across circuits.

```{r average lap time per circuit, echo=FALSE}
df_timedata %>%
  ggplot(aes(fct_reorder(as.factor(circuitId), avg_lap), avg_lap)) + 
  geom_boxplot() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) + 
  labs(
    x = "Circuit ID number",
    y = "Average lap time (ms)"
  )
```

The average lap time varies across circuits due to the differences in track length and shape, so we need a way to compare average lap time across circuits. Dividing average lap time by average lap time per circuit doesn't work because it doesn't account for the range of average lap time on each circuit. To correct for the impact of circuit on average lap time, we standardized by circuit:

$$\mu = \sum_{i}^{n} \frac{x_i}{n}$$

$$\sigma = \sqrt{\sum_{i}^{n} \frac{(x_i - \mu)^2}{n}}$$

$$z = \frac{x-\mu}{\sigma}$$

where $x$ is the data, $\mu$ is the mean, $\sigma$ is the standard deviation, and $z$ is the standard score of $x$

#### Standardized Average Lap Time by Circuit

```{r, echo = FALSE}
df_timedata %>%
  ggplot(aes(fct_reorder(as.factor(circuitId), std_avg_lap), std_avg_lap)) +
  geom_boxplot() + 
  labs(
    x = "Circuit ID number",
    y = "standardized average lap time"
#    title = "Comparing standardized average lap time by circuit"
  ) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

The graph above shows a visual comparison of standardized average lap time by circuit. The slope of the median is small in magnitude relative to the range of the standardized average lap time, showing that standardizing the average lap time successfully minimizes the effect of circuit. 

#### Driver and Constructor by Standardized Average Lap Time

```{r fig.width = 20,fig.height=10, echo=FALSE,  warning = FALSE}
#df_timedata %>%
#  mutate(driver_name = fct_reorder(as.character(driver_name),std_avg_lap))%>%
#  ggplot(mapping = aes(x = driver_name, y = std_avg_lap)) +
#  geom_boxplot() +
#  theme_minimal() +
##  ylim(-2,2) +
#  theme(axis.text.x = element_text(angle = 90,vjust = 0.5, hjust = 1))+
#  labs(x = "Driver Name",y = "Standardized Average Lap Time (ms)")

df_timedata %>%
  mutate(constructor_name = fct_reorder(as.character(constructor_name),std_avg_lap))%>%
  ggplot(mapping = aes(x = constructor_name, y = std_avg_lap)) +
  geom_boxplot()+
  theme_minimal() +
  ylim(-2,2) +
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5, hjust = 1))+
  labs(x = "Vehicle Constructor Name",y = "Standardized Average Lap Time (ms)")
```

Constructor and standardized average lap time appear to have a positive and fairly linear relationship. This makes sense because standardizing should correct the distribution to become more linear. Seeing that constructor has an impact on standard average lap time is a good sign because it indicates that there may be some causality and therefore also predictive capability.

#### Modeling by standard average lap time

First, let's model the `a subset of the data that has completed times` to get a sense of how informative a linear model is for our dataset, solely based upon driver, constructor, and a combination of the two.

```{r modeling the entire data set with train & validate, echo = TRUE}
f_driv_sal <-
  df_timedata %>%
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(driverId)
  )

f_cons_sal <- 
  df_timedata %>% 
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(constructorId)
  )

f_drivcons_sal <- 
  df_timedata %>% 
  lm(
    data = .,
    formula = std_avg_lap ~ as.factor(driverId) + as.factor(constructorId)
  )
```

```{r full fit output, echo = FALSE}
cat("Full Fit - Just Driver", "\n")
cat("  Rsquare", rsquare(f_driv_sal, df_timedata), "\n")
cat("  MSE", mse(f_driv_sal, df_timedata), "\n")

cat("Full Fit - Just Constructor", "\n")
cat("  Rsquare", rsquare(f_cons_sal, df_timedata), "\n")
cat("  MSE", mse(f_cons_sal, df_timedata), "\n")

cat("Full Fit - Driver and Constructor", "\n")
cat("  Rsquare", rsquare(f_drivcons_sal, df_timedata), "\n")
cat("  MSE", mse(f_drivcons_sal, df_timedata), "\n")
```

Starting with looking at the mean square error (MSE) we can compare the different fits against one another. Between fits, the error is lowest wiTth both `driver and constructor`. The "goodness of fit" is best with both factors involved, which may imply that both are informative towards standard average lap time. However, the difference is quite small between MSEs, so the predictive capabilities of both still seem minute. The order of best to worst fit, solely based upon MSE, is **driver and constructor, just driver, and finally just constructor.** These results may imply that driver is a better predictor of outcome than constructor, but this is not necessarily the case. 

Looking next at our R-square value we see that our models **do not** encapsulate much of the variance of the data. We see the fraction of the 

These models should be taken with a grain or more of salt as we are using the entire data set to create them, so we don't have a separate training and validation data set. However, using a split of the dataset for training and the rest for validation will not increase the accuracy of the model. With such a low predictive capability already it doesn't appear to be useful to fit additional models.

## Final Position Order

#### Driver and Constructor by Final Position Order
```{r, echo=FALSE}
dataFile <- "processed_data/clean_f1.csv"
df_cleanLapTimes <- read.csv(dataFile)
```


```{r fig.width = 20,fig.height=15, echo=FALSE}
df_cleanLapTimes %>%
  filter(year >= 2014)%>%
  mutate(driver_name = fct_reorder(as.character(driver_name),positionOrder))%>%
  ggplot(mapping = aes(x = driver_name, y = positionOrder)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5, hjust = 1))+
  labs(x = "Vehicle Driver Name", y = "Final Position Ranking")
```

We can see that when we plot the final position vs the driver of the vehicle there does seem to be a correlation. in that some drivers tend to outperform the average and some drivers tend to underperform the average. If we examine the names the highly performing racers tend to be the racers more well renown for their skill such as [Louis Hamelton]() and [](). This suggests that there is a correlation between the driver performance and the standing in the race and we can see this play out in the relatively linear relation between the two variables. An interesting relation we can see in the data are 'plateaus' in the median values where there are sets of drivers with similar performances. 

```{r echo=FALSE}
df_cleanLapTimes %>%
  filter(year >= 2014)%>%
  mutate(constructor_name = fct_reorder(as.character(constructor_name),positionOrder))%>%
  ggplot(mapping = aes(x = constructor_name, y = positionOrder)) +
  geom_boxplot() +
  theme(axis.text.x = element_text(angle = 90,vjust = 0.5, hjust = 1)) +
  labs(x = "Vehicle Constructor Name",y = "Final Position Ranking")
```

When we plot the constructor vs the final position order we see generally that the higher performing constructors are associated with a low position order, and the lower performing constructors are associated with a lower position order, however this is not a linear relationship. The highest performing constructors account for most of the low final position orders and the lowest performing constructors account for much of the high final position orders. But middle performing constructors all seem to have similar performance.

Taken together we can see that the driver and constructor graphs are correlated with the final position order so it is likely that both of them help account for the final position order, but they might not be the sole determining factors. The more linear relationship of driver with final position order suggests that the driver is slightly more predictive of the final position order than the less linear vehicle constructor.

#### Modeling Using Final Position Order

```{r split data into train & validate, echo = TRUE }
df_data_with_rows <- tibble::rowid_to_column(df_data, "ID")

df_train_pos <-
  df_data_with_rows %>%
  #group_by(driverId, constructorId, circuitId) %>% 
  slice_sample(n = 12450) # %>% 
 # ungroup()

df_validate_pos <-
  anti_join(
    df_data_with_rows,
    df_train_pos,
    by = "ID"
  )

df_train_pos
df_validate_pos
```

```{r modeling using positionOrder, echo = TRUE}
f_driv_pos <-
  df_train_pos %>%
  lm(
    data = .,
    formula = positionOrder ~ as.factor(driverId)
  )

f_cons_pos <- 
  df_train_pos %>% 
  lm(
    data = .,
    formula = positionOrder ~ as.factor(constructorId)
  )

f_drivcons_pos <- 
  df_train_pos %>% 
  lm(
    data = .,
    formula = positionOrder ~ as.factor(driverId) + as.factor(constructorId)
  )
```

```{r train fit outputs, echo = FALSE, warning = FALSE}
cat("Train Fit - Just Driver", "\n")
cat("  Rsquare", rsquare(f_driv_pos, df_validate_pos), "\n")
cat("  MSE", mse(f_driv_pos, df_validate_pos), "\n")

cat("Train Fit - Just Constructor", "\n")
cat("  Rsquare", rsquare(f_cons_pos, df_validate_pos), "\n")
cat("  MSE", mse(f_cons_pos, df_validate_pos), "\n")

cat("Train Fit - Driver and Constructor", "\n")
cat("  Rsquare", rsquare(f_drivcons_pos, df_validate_pos), "\n")
cat("  MSE", mse(f_drivcons_pos, df_validate_pos), "\n")
```

#### Probability Intervals

If possible given your data, report all estimates with confidence / prediction / tolerance intervals. If not possible, clearly explain why it is not possible to provide intervals and document what sources of uncertainty are not quantified.


----------------------------------------

## Conclusion

testing testing testing

----------------------------------------

## Rubrics

Questions to answer:

- What question did you set out to answer?
- What data did you find to help answer that question?
- What is the relevant background on your question?
- What level of (quantified) certainty do you have in your results?
- What conclusions did you come to?
- What questions do you have remaining?
- Make sure your report contains at least one presentation-quality figure

Observed:

- (The usual stuff)
- Must provide background
- Must posit a question

Supported:

- (The usual stuff)
- Some analysis must support answering question

Assessed:

- (The usual stuff)
- All estimates must be provided with some quantification of uncertainty (e.g. confidence / prediction / tolerance intervals), OR a justification for why producing an interval is not possible and documentation for sources of uncertainty not accounted for.

Styled:

- (The usual stuff)
- Report must contain at least one presentation-quality figure

